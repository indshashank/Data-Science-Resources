{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "### High Level Summary\n",
    "Logistic regression is an algorithm for classifying data samples into one of K discrete classes. In the case that K = 2, the term binary logistic regression may be used, and when K > 2 multinomial logistic regression is used. If the classes have order, ordinal logistic regression is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary logistic regression\n",
    "\n",
    "Assume that the target value, y, can be either 1 or 0 (i.e. $y \\in \\{0,1\\}$). We could just treat this like linear regression where we build up a score ($\\vec{\\theta}^T \\vec{x}$) and a higher score may mean y is more likely to be 1 while a lower score indicates y is likely to be zero. There are several problems with this and it is easy to find cases where this model does not work well [citation needed]. Additionally, it is not intuitive to predict values outside the interval [0, 1].\n",
    "\n",
    "Instead, we'll choose a model that predicts value within the interval [0, 1] using the logit function. There are good reasons that this function is chosen, but we'll not go into them here (beyond the reasons stated already). The linear combination of the input vector is now chosen to vary with the logit of the probability p.\n",
    "\n",
    "$$ \\ln{\\frac{p}{1-p}} = \\vec{\\theta}^T \\cdot \\vec{x} $$\n",
    "\n",
    "Solving for p,\n",
    "\n",
    "$$ p(y = 1|\\vec{x};\\vec{\\theta}) = h_{\\theta}(\\vec{x}) = \n",
    "\\frac{1}{1 + e^{-\\vec{\\theta}^T \\cdot \\vec{x}}} \\\\\n",
    "p(y = 0|\\vec{x};\\vec{\\theta}) = 1 - p(y = 1|\\vec{x};\\vec{\\theta}) = \n",
    "\\frac{e^{-\\vec{\\theta}^T \\cdot \\vec{x}}}{1 + e^{-\\vec{\\theta}^T \\cdot \\vec{x}}}\n",
    "$$\n",
    "\n",
    "Written more compactly, we have the probability of y being what it is, given the data (x vector):\n",
    "\n",
    "$$\n",
    "p(y;\\vec{x};\\vec{\\theta}) = h_{\\theta}(\\vec{x})^y \\cdot \\left(1 - h_{\\theta}(\\vec{x})\\right)^{1 - y}\n",
    "$$\n",
    "\n",
    "Remember that when y = 1, the second term goes away and the probability is just $h_{\\theta}$ and when y = 0, the probability becomes $1 - h_{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation above is for a single sample. What we really want to do is to maximize the equation above taking into account all samples. Basically, maximize the aggregate likelihood of all the data, given the feature vectors. We can do this by multiplying their likelihoods together, which means we're multiplying a bunch of numbers that vary between [0, 1] together, so the result also varies between [0, 1].\n",
    "\n",
    "$$\n",
    "L(\\vec{\\theta}) = \\prod_{i=1}^m p(y^i|\\vec{x}^i;\\vec{\\theta})\n",
    "= \\prod_{i=1}^m h_{\\theta}(\\vec{x}^i)^{y^i} \\cdot \\left(1 - h_{\\theta}(\\vec{x}^i)\\right)^{1 - y^i}\n",
    "$$\n",
    "\n",
    "We can transform $L(\\vec{\\theta})$ into its log form which is easier to maximize. Maximizing the log form of the likelihood with respect to the parameter vector $\\vec{\\theta}$ is equivalent to maximizing the original likelihood function.\n",
    "\n",
    "$$\n",
    "\\ell(\\vec{\\theta}) = \\ln{L(\\vec{\\theta})} = \n",
    "\\sum_{i=1}^m y^i\\ln{h_{\\theta}(\\vec{x}^i)} \\cdot (1 - y^i) \\ln{\\left(1 - h_{\\theta}(\\vec{x}^i)\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we need to find a $\\theta$ vector that maximizes the equation above. How? One way is to use gradient ascent, which is a common optimization function.\n",
    "\n",
    "In gradient ascent, we wish to start with a guess for the parameter vector, and then somehow intelligently update that guess until we get to the best answer. To do this, we find the gradient of the likelihood function with respect to $\\theta$ and step in that direction. So, for each $\\theta_j$ in $\\vec{\\theta}$ we update our guess by:\n",
    "\n",
    "$$\n",
    "\\vec{\\theta}_j = \\vec{\\theta}_j + \\alpha\\frac{\\partial}{\\partial \\vec{\\theta}_j} \\ell(\\vec{\\theta})\n",
    "$$\n",
    "\n",
    "We need to find the gradient of the likelihood function with respect to theta first.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{\\theta}_j} \\ell(\\vec{\\theta}) = \n",
    "\\left(y \\frac{1}{h_{\\theta}(\\vec{x})} - (1 - y) \\frac{1}{1- h_{\\theta}(\\vec{x})} \\right) \\frac{\\partial}{\\partial \\vec{\\theta}_j} h_{\\theta}(\\vec{x}) \\\\ \n",
    "= \\left(y \\frac{1}{h_{\\theta}(\\vec{x})} - (1 - y) \\frac{1}{1- h_{\\theta}(\\vec{x})} \\right)  h_{\\theta}(\\vec{x})(1 - h_{\\theta}(\\vec{x})) \\frac{\\partial}{\\partial \\vec{\\theta}_j} \\left( \\vec{\\theta}^T \\vec{x} \\right) \\\\\n",
    "= \\left(y \\frac{1}{h_{\\theta}(\\vec{x})} - (1 - y) \\frac{1}{1- h_{\\theta}(\\vec{x})} \\right)  h_{\\theta}(\\vec{x})(1 - h_{\\theta}(\\vec{x})) x_j \\\\\n",
    "= \\left(y - h_{\\theta}(\\vec{x}) \\right) x_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leads to the gradient ascent update and, further, a stochastic update:\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j + \\alpha\\sum_{i=1}^m \\left(y^i - h_{\\theta}(\\vec{x}^i) \\right) x^i_j \\\\\n",
    "\\theta_j = \\theta_j + \\alpha \\left(y^i - h_{\\theta}(\\vec{x}^i) \\right) x^i_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
